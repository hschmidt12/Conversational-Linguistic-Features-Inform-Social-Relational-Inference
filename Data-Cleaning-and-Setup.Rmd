---
title: "Data Cleaning And Setup"
subtitle: "Conversational Linguistic Features Predict Social Network Learning"
author: "Helen Schmidt"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    theme: cerulean
    toc: yes
    toc_float: yes
    code_folding: hide
---
<style>
h1, h2, h3, h4, h5, h6, legend {
    color: #1c3aa9;
}
</style>

**This script should be run before running any of the analysis scripts (Study 1, Study 2, Study 3).**

```{r warning = FALSE, message = FALSE, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(ggplot2)
library(tidytext)
library(readr)
library(knitr)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(tm)
library(SnowballC)
library(XML)
library(RCurl)
library(ggpubr)
library(wesanderson)
library(reshape2)
library(MetBrewer)
library(sentimentr)
library(sna)
library(splitstackshape)
library(GGally)
library(ggraph)
library(gutenbergr)
library(igraph)
library(Matrix)
library(network)
library(tidygraph)
library(tibble)
library(formattable)
library(forcats)
library(lme4)
library(ggthemes)
library(lmerTest)
library(misty)
library(Rmisc)
library(effects)
library(arm)
library(stringr)
library(sjPlot)
library(lattice)
library(devtools)
library(sjmisc)
library(ggeffects)
library(reghelper)
library(glmmTMB)
library(reactable)
library(reactablefmtr)
library(tidyr)
library(dplyr)
library(janitor)
library(skimr)
library(corrplot)
library(bmlm)
library(stargazer)
```

```{r}
# set up themes and notebook-wide settings
my.alpha = .2
colors <- c("#2185c5ff","#ff9715ff","#f20253ff","#7ecefdff","#1c3aa9ff")
se <- function(x) sqrt(var(x)/length(x))  #function to calculate SE
```

```{r, setup, include = FALSE}
# set global wd 
knitr::opts_knit$set(root.dir = "/Volumes/GoogleDrive/My Drive/SANLab/Experiments/Survivor-Language/Analysis/") 
# set to 3 decimal places for entire markdown
options(digits = 5)
```

**Background**  
The first section of this Markdown pulls in and wrangles two types of data - behavioral responses and episode transcriptions. The behavioral responses come from 57 participants who completed the Survivor task. They watched an episode from Survivor (split into six clips) and made up to 630 responses about which of the contestants were better friends, rivals, or more likely to win the game. There were seven contestants remaining in the game during this episode - Alicia, Amber, Rob, Rupert, Jenna, Shii Ann, and Tom. 

**Behavioral Task Design**  
During each trial, participants were presented with a target image of one contestant and two choices of two other contestants from the episode. The participant was asked to judge (binary choice) which of the two choices was either better friends with, bigger rivals of, or more likely to win than the target contestant. Each trial presented a new target and two new choices. However, during each block (one response block was completed after viewing each of the six episode clips), the *question* did not change. 

**Formatting Choice Data**  
First, I took the raw responses and calculated the percent of time a given contestant was chosen when presented as an option for a given target. This involved dividing how many times a contestant was chosen relative to each target by how many times that contestant was presented as an option.

```{r}
## Load and format behavioral choice data ##

# load raw choice behavioral data
data <- read.csv("./Paper-Analysis/data/dat_survivor.csv")

# capitalize first names when they are targets, left images, or right images
capFirst <- function(s) {paste(toupper(substring(s, 1, 1)), substring(s, 2), sep = "")}
data$Target <- capFirst(data$Target)
data$LeftPersonImg <- capFirst(data$LeftPersonImg)
data$RightPersonImg <- capFirst(data$RightPersonImg)
data$choice <- capFirst(data$choice)
# remove space from Shii Ann's name for ease of plotting
data[data == "Shii Ann"] = "ShiiAnn"
data[data == "Shiiann"] = "ShiiAnn"
# name clips to match text data 
names(data)[8] <- "ClipNumber"
# reformat choice data
unique.targets <- unique(data$Target)
unique.choices <- unique(data$choice)
formatted.choices <- data.frame()

# calculate % time chosen
for (x in 1:length(unique(data$Target))) {
  all.choices <- data.frame()
  # subset to one target only
  test <- subset(data, data$Target == unique.targets[x])
  # loop through possible choices
  for (y in 1:length(unique(data$choice))) {
    # how many times was each person an option?
    choices <- subset(test, c(test$LeftPersonImg == unique.choices[y] | test$RightPersonImg == unique.choices[y]))
    # group by sub ID & clip #, count the number of times someone appears as a choice vs % time chosen
    choices <- choices %>%
      group_by(PID,Target,condType,ClipNumber) %>%
        mutate(n = str_count(choice, unique.choices[y])) %>%
          summarize(option = length(Target),
                    selected = sum(n))
    # add in choice name
    choices$ChoiceOption <- unique.choices[y]
    # calculate percent of time chosen
    choices <- choices %>%
      group_by(PID,ClipNumber,condType,Target,ChoiceOption) %>%
        summarize(percent.chosen = selected/option)
    # save choices into new data frame
    all.choices <- rbind(all.choices, choices)
  }
  # save all targets into new data frame
  formatted.choices <- rbind(formatted.choices, all.choices)
}

# This loop gives the friendly warning:
# `summarise()` has grouped output by 'PID', 'ClipNumber', 'condType', 'Target'. You can override using the `.groups` argument. 
# This is not an issue, it is just telling me which columns I've grouped by before summarizing. 

# remove data frames that are no longer needed
rm(all.choices)
rm(choices)
rm(test)

# show data frame
reactable(head(formatted.choices),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)
```

**Formatting Transcribed Dialogue**  
Next, I loaded the transcribed dialogue from this episode. Two coders independently transcribed the whole episode, making note of the speaker (who is talking), what the speaker is saying (the dialogue in question), the recipient (who the speaker is talking to), and the clip number that dialogue is coming from (clips 1 - 6).

I removed any observation of the host, Jeff Probst, speaking as we were not interested in examining his dialogue.

```{r}
## Load dialogue and format with linguistic features ##

# load dialogue from episode
dialogue <- read.csv("./Paper-Analysis/data/survivor-text.csv")
# make sure dialogue, speaker, and recipient are character vectors
dialogue$Dialogue <- as.character(dialogue$Dialogue)
dialogue$Speaker <- as.character(dialogue$Speaker)
dialogue$Recipient <- as.character(dialogue$Recipient)
# remove space from Shii Ann's name for ease of plotting
dialogue$Speaker[dialogue$Speaker == "Shii Ann"] = "ShiiAnn"
dialogue$Recipient[dialogue$Recipient == "Shii Ann"] = "ShiiAnn"

# show data frame
reactable(head(dialogue),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)
```

**Calculating Sentiment using sentimentr (NLP package in R)**  
I next used an NLP package in R called `sentimentr` to divide the dialogue such that each row in my data frame contained one sentence of dialogue. I then used this package to calculate a sentiment score and a polarity level for each sentence. Sentiment scores indicate how positive or negative a sentence's tone or affect is. The sentiment score is calculated by comparing the words to a dictionary and taking into account the words around each affective word. The algorithm within `sentimentr` then calculates a weighted score for the sentence and assigns the sentence a polarity of negative, neutral, or positive depending on that weighted score. I manually defined scores that were less than zero to be "negative", scores that were greater than zero to be "positive", and scores that were zero exactly to be "neutral". Sentiment scores range from around -1 to 1.

**Adding Clout using LIWC**  
Using the linguistic inquiry and word count (LIWC) software, a gold standard for analyzing word use, I also calculated a clout score for each sentence. Clout can be defined as confidence or self-assurance and is calculated in a similar way to sentiment (although the exact method is not known, given LIWC's secrecy around their algorithms). Clout scores range from 1 - 100, with scores greater than 50 indicating higher clout and scores less than 50 indicating lower clout.

I merged these two linguistic measures with the transcribed dialogue from the episode. 

```{r}
## Add sentiment and clout scores to dialogue ##
sent_dialogue <- dialogue 
sent_dialogue$order <- 1:nrow(sent_dialogue)
# get polarity html, opens in browser
sent_dialogue <- sent_dialogue %>%
  mutate(sentences = get_sentences(Dialogue)) %$%
  sentiment_by(sentences, Speaker) %>%
  highlight(file = "polarity.html")

# CALCULATE SENTIMENT USING SENTIMENTR #
# add sentiment scores & polarity levels for each sentence
dialogue <- dialogue %>% 
  get_sentences() %>% #get each sentence
  sentiment() %>% #get sentiment score
  #make scores < 0 "negative" and scores > 0 "positive"
  mutate(polarity_level = ifelse(sentiment < 0, "Negative", 
                                 #else, make scores = 0 "neutral"
                                 ifelse(sentiment > 0, "Positive","Neutral"))) 
dialogue$order <- 1:nrow(dialogue)

# ADD CLOUT SCORES FROM LIWC #
# read in csv with one sentence per row and LIWC calculated clout score
clout <- read.csv("./Paper-Analysis/data/LIWC_clout.csv")
# add sentence order count to help with merge
clout$order <- 1:nrow(clout)
# remove extra columns, keeping only clout score and sentence order
clout <- clout[,c(1,2,3,11,12)]
# change names
names(clout)[1] <- "ClipNumber"
names(clout)[2] <- "Speaker"
names(clout)[3] <- "Recipient"
names(clout)[4] <- "clout"

# merge clout scores into dialogue data frame
dialogue <- merge(dialogue, clout, by = c("order","Speaker","Recipient","ClipNumber"))
# remove recipient type, not needed
dialogue <- dialogue[,-6]
# remove host as a speaker
dialogue <- subset(dialogue, dialogue$Speaker != "Probst")

# show data frame
reactable(head(dialogue),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)

```

**Calculating mean clout and sentiment**  
Now, I calculate average sentiment and clout per speaker, averaged across all their dialogue from the whole episode. Then, I calculate overall (averaged across the whole episode), most recent (averaged within each individual episode clip), and cumulative (averaged across each successive episode clip) clout and sentiment. These are specific to a speaker-recipient pair. For example, calculating most recent sentiment from clip #4 between Amber (speaker) and Rob (recipient) would mean averaging all sentiment scores from all dialogue spoken by Amber to Rob in clip #4.

```{r}
## Calculate average sentiment and clout per speaker ##

dialogue <- dialogue %>%
  group_by(Speaker) %>%
  mutate(speaker.sentiment = mean(sentiment),
         speaker.clout = mean(clout))

## Calculate overall, most recent, and cumulative clout and sentiment for each target-choice pair ##

# overall 
dialogue <- dialogue %>%
  group_by(Speaker,Recipient) %>%
  mutate(overall.sentiment = mean(sentiment),
         overall.clout = mean(clout))

# most recent
dialogue <- dialogue %>%
  group_by(Speaker,Recipient,ClipNumber) %>%
  mutate(recent.sentiment = mean(sentiment),
         recent.clout = mean(clout))

# cumulative
for (i in 1:length(unique(dialogue$ClipNumber))) {
  # average scores across only clip 1
  if (i == 1) {
    test <- subset(dialogue, dialogue$ClipNumber == 1)
    clip1 <- test %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip1$ClipNumber <- 1}
  # average scores across clip 1 + 2
  else if (i == 2) {
    test <- subset(dialogue, c(dialogue$ClipNumber == 1 | dialogue$ClipNumber == 2))
    clip2 <- test %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip2$ClipNumber <- 2}
  # average scores across clip 1, 2, + 3
  else if (i == 3) {
    test <- subset(dialogue, c(dialogue$ClipNumber == 1 | dialogue$ClipNumber == 2 | dialogue$ClipNumber == 3))
    clip3 <- test %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip3$ClipNumber <- 3}
  # average scores across clip 1, 2, 3, + 4
  else if (i == 4) {
    test <- subset(dialogue, c(dialogue$ClipNumber == 1 | dialogue$ClipNumber == 2 | dialogue$ClipNumber == 3 | dialogue$ClipNumber == 4))
    clip4 <- test %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip4$ClipNumber <- 4}
  # average scores across clip 1, 2, 3, 4, + 5
  else if (i == 5) {
    test <- subset(dialogue, dialogue$ClipNumber != 6) 
    clip5 <- test %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip5$ClipNumber <- 5}
  # average sentiment scores across all clips
  else if (i == 6) {
    clip6 <- dialogue %>%
      group_by(Speaker,Recipient) %>%
        summarize(cumulative.sentiment = mean(sentiment),
                  cumulative.clout = mean(clout))
    clip6$ClipNumber <- 6}
}

# This loop gives the friendly warning:
# `summarise()` has grouped output by 'Speaker'. You can override using the `.groups` argument.
# This is not an issue, it is just telling me which columns I’ve grouped by before summarizing.

# merge cumulative scores
cumulative <- rbind(clip1,clip2,clip3,clip4,clip5,clip6)
# add cumulative scores to dialogue
dialogue <- merge(dialogue,cumulative, by = c("Speaker","Recipient","ClipNumber"))

# show data frame
reactable(head(dialogue),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)
```

**Pull in Similarity scores from the Universal Sentence Encoder**  
The final linguistic feature I'll analyze is similarity. Similarity scores represent a correlation between the dimensional values of one contestant's dialogue and another contestant's dialogue. Unlike sentiment and clout, similarity is 1) non-directional, that is, there is one similarity score per contestant pair regardless of who is speaking. Similarity is also 2) not sentence specific, that is, there is not a unique similarity score per sentence of dialogue. Additionally, in the context of the "overall", "most recent", and "cumulative" calculations for clout and sentiment, similarity most closely matches "most recent", since it is calculated on a clip-by-clip basis.

```{r}
## Get similarity scores for each contestant pair ##

# Calculated using USE, see Survivor-USE R Markdown
# Uses all dialogue from contestants only, spoken to other contestants, to the camera, and to the tribe as a group!

# Similarity scores are assigned to each speaker-recipient pair per episode clip (6 total). There will be one similarity score per unique contestant pair, but we will NOT have a similarity score per sentence like we do for clout and sentiment. This scores represent a correlation between the two contestants in the pair, and does not change depending on who is the speaker and who is the recipient.

# read in csv with similarity correlations calculated from USE
similarity = list.files("./Paper-Analysis/data/clips",
                      full.names = TRUE,
                      pattern="*.csv",
                      recursive = TRUE)
# bind data and add column for subject ID
similarity  = do.call(rbind, lapply(similarity, function(x) { data = read.csv(x, header = TRUE)
                                                         pos = regexpr('clip', x)
                                                         data$ClipNumber = substr(x, pos+10, pos+10)
                                                         return(data)
                                                         } ))
# name first column Person1
names(similarity)[1] <- "Speaker"
# pivot longer to create Person2 column
similarity <- pivot_longer(similarity,
                           cols = Alicia:Tom,
                           names_to = "Recipient",
                           values_to = "recent.similarity")
# make sure Person1 and Person2 are character vectors
similarity$Speaker <- as.character(similarity$Speaker)
similarity$Recipient <- as.character(similarity$Recipient)
# make sure ClipNumber is numeric
similarity$ClipNumber <- as.numeric(similarity$ClipNumber)

# show data frame
reactable(head(similarity),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)

# save similarity scores
write.csv(similarity, "./Paper-Analysis/data/Similarity-data.csv", row.names = F)
```

**Merge similarity scores with rest of dialogue**  
Then, I can merge the similarity scores with the rest of the dialogue!

```{r}
## Add similarity scores to dialogue ##

dialogue <- merge(dialogue, similarity, by = c("Speaker","Recipient","ClipNumber"), all.x = T)
# now dialogue has a clout score per sentence, a sentiment score per sentence, and a similarity score per speaker/recipient pair (one value per clip number regardless of speaking direction)

# show dialogue
reactable(head(dialogue),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)

# plot dialogue word counts for each speaker
pp <- met.brewer(name = "Hiroshige")
pp_vec <- c(pp[1], pp[2], pp[4], pp[6], pp[7], pp[8], pp[9])
ggplot(dialogue, aes(x = order, y = word_count, color = Speaker)) +
  geom_line(aes(group = Speaker), alpha = .3) +
  geom_smooth(aes(group = Speaker), se = FALSE) +
  ylab("word count") +
  ylim(0, 35) +
  theme_classic() +
  ggtitle("Character word count over the course of the episode") +
  labs(x = "Time") +
  scale_color_manual(values = pp_vec) +
  theme(panel.background = element_blank())

```

**Match dialogue with choice data**  
Finally, the exciting step is matching these three linguistic features (similarity, sentiment, and clout) with the behavioral choice data. This will allow me to analyze to what extent participants use each linguistic feature to inform their decisions about friendship, rivalry, and likelihood of winning. 

Since participants make relationship decisions about all contestants, but not all contestants speak to one another in each episode clip, I ultimately have to include *only* trials where there is linguistic information that corresponds to the behavioral data. For example, if Amber speaks to Alicia in clip #3, we would have linguistic information for all instances where Amber is a target and Alicia is a presented choice. However, if Alicia does not say anything to Amber in clip #3, we would *not* have linguistic information for instances where Alicia is a target and Amber is a presented choice. Therefore, we would have to drop those trials. 

```{r}
## Merge linguistic features (dialogue) with choice data (formatted.choices) ##

# format new dialogue information data frame to merge with the choice data
ling.features <- dialogue
# change speaker and recipient variable names to match choice data
names(ling.features)[1] <- "Target"
names(ling.features)[2] <- "ChoiceOption"
# pull features scores for each target/choice option per clip
# not actually getting a new mean, but rather collapsing to get simplified data frame
ling.features <- ling.features %>%
  group_by(Target, ChoiceOption, ClipNumber) %>%
  summarize(speaker.sentiment = mean(speaker.sentiment),
            speaker.clout = mean(speaker.clout),
            overall.sentiment = mean(overall.sentiment),
            recent.sentiment = mean(recent.sentiment),
            cumulative.sentiment = mean(cumulative.sentiment),
            overall.clout = mean(overall.clout),
            recent.clout = mean(recent.clout),
            cumulative.clout = mean(cumulative.clout),
            recent.similarity = mean(recent.similarity),
            mean.wordcount = mean(word_count))

# merge into new clean data frame with features and behavioral data; this will inclue NAs for trials where there is no corresponding linguistic data
df.clean <- merge(formatted.choices, ling.features, by = c("Target","ChoiceOption","ClipNumber"), all.x = T)
# save df.clean (all trials, including NAs where there is no sentiment/clout data)
write.csv(df.clean, "./Paper-Analysis/data/df-clean.csv", row.names = F)

# get a subset of only trials with corresponding linguistic data 
df.ling <- subset(df.clean, !is.na(df.clean$overall.sentiment) & !is.na(df.clean$recent.sentiment) 
                  & !is.na(df.clean$cumulative.sentiment)
                  & !is.na(df.clean$overall.clout) & !is.na(df.clean$recent.clout) & !is.na(df.clean$cumulative.clout) 
                  & !is.na(df.clean$recent.similarity))
# call condType BlockType
names(df.ling)[5] <- "BlockType"

# save df.ling (all trials that have corresponding sentiment/clout data)
write.csv(df.ling, "./Paper-Analysis/data/df-ling.csv", row.names = F)

# show final data frame with only included trials
reactable(head(df.ling),
          outlined = T, striped = T,
          style = list(fontFamily = "Avenir", fontSize = "12px"),
          compact = T,
          resizable = T,
          wrap = F)

```