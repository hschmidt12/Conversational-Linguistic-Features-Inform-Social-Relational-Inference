---
title: "Study 2 -- Linguistic Features"
subtitle: "Conversational Linguistic Features Predict Social Network Learning"
author: "Helen Schmidt"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    theme: cerulean
    toc: yes
    toc_float: yes
    code_folding: hide
---
<style>
h1, h2, h3, h4, h5, h6, legend {
    color: #1c3aa9;
}
</style>

# Setup

```{r warning = FALSE, message = FALSE, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(ggplot2)
library(tidytext)
library(readr)
library(knitr)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
library(tm)
library(SnowballC)
library(XML)
library(RCurl)
library(ggpubr)
library(wesanderson)
library(reshape2)
library(MetBrewer)
library(sentimentr)
library(sna)
library(splitstackshape)
library(GGally)
library(ggraph)
library(gutenbergr)
library(igraph)
library(Matrix)
library(network)
library(tidygraph)
library(tibble)
library(formattable)
library(forcats)
library(lme4)
library(ggthemes)
library(lmerTest)
library(misty)
library(Rmisc)
library(effects)
library(arm)
library(stringr)
library(sjPlot)
library(lattice)
library(devtools)
library(sjmisc)
library(ggeffects)
library(reghelper)
library(glmmTMB)
library(reactable)
library(reactablefmtr)
library(tidyr)
library(dplyr)
library(janitor)
library(skimr)
library(corrplot)
library(bmlm)
library(stargazer)
library(patchwork)
```

```{r}
# set up themes and notebook-wide settings
my.alpha = .15
colors <- c("#2185c5ff","#ff9715ff","#f20253ff","#7ecefdff","#1c3aa9ff")
#colors <- c("#264653","#2a9d8f","#e9c46a","#f4a261","#e76f51")
# set friend/rivalry colors
fr.colors <- c(colors[2], colors[3])
se <- function(x) sqrt(var(x)/length(x))  #function to calculate SE
theme_set(theme_classic())
```

```{r, setup, include = FALSE}
# set global wd 
knitr::opts_knit$set(root.dir = "/Volumes/GoogleDrive/My Drive/SANLab/Experiments/Survivor-Language/Analysis/") 
# set to 3 decimal places for entire markdown
options(digits = 10)
```

```{r}
df.clean <- read.csv("./Paper-Analysis/data/df-clean.csv")
df.ling <- read.csv("./Paper-Analysis/data/df-ling.csv")
similarity <- read.csv("./Paper-Analysis/data/Similarity-data.csv")
transcript <- read.csv("./Paper-Analysis/data/survivor-split-sentences.csv")

# print number of sentences/items of dialogue
# remove dialogue spoken by host
transcript <- subset(transcript, Speaker != "Probst")
numObs <- nrow(transcript)
print(paste0("Number of sentences of dialogue = ", numObs, sep = ""))
```

# Linguistic Feature Models (F/R)

## Similarity

**Note: I'm not mean centering similarity because similarity scores correspond to correlations. A similarity score of 0 is meaningful and I won't have negative similarity scores (USE calculation).**

See more information [here](https://www.theanalysisfactor.com/when-not-to-center-a-predictor-variable-in-regression/).

### Format data

```{r}
# get mean % time chosen per clip, averaged across participants
all_choices <- df.clean %>%
  select(Target, ChoiceOption, ClipNumber, PID, condType, percent.chosen)

# add "Speaker" and "Recipient" columns
all_choices$Speaker <- all_choices$Target
all_choices$Recipient <- all_choices$ChoiceOption

# add dyad pair column
all_choices <- data.frame(all_choices, stringsAsFactors = F) %>%
  mutate(dyad = paste0(pmin(Target,ChoiceOption), pmax(Target,ChoiceOption), sep=""))

# join choices and similarity scores
overall_sim <- inner_join(all_choices, similarity)
overall_sim <- overall_sim %>%
  filter(recent.similarity < .99) # remove high similarity between Alicia/Tom

# save
write.csv(overall_sim, "/Volumes/GoogleDrive/My Drive/SANLab/Experiments/Survivor-Language/Analysis/Paper-Analysis/data/similarity_choices.csv")
```

Look at simple slopes for when condType is friend and rival. This indicates the relationship between similarity and % of time chosen when in a friend block or a rival block. I am testing if that value is significantly different from zero. Similarity is the moderator!

```{r}
# only include friend and rival judgments
friend.rival <- subset(overall_sim, condType != "Win")

# make condType a factor
friend.rival$condType <- as.factor(friend.rival$condType)

test <- subset(overall_sim, condType == "Friend")
test.model <- lmer(percent.chosen ~ recent.similarity + (1|dyad) + (1|PID), data = test)
summary(test.model)

# run multilevel model
model.similarity <- lmer(percent.chosen ~ recent.similarity * condType + (1|dyad) + (1|PID),
                         data = friend.rival)
summary(model.similarity)
# get confidence intervals
confint(model.similarity)
# get simple slopes
simple_slopes(model.similarity)
# plot simple slopes
graph_model(model.similarity, y=percent.chosen, x=condType, lines=recent.similarity, colors = fr.colors)
```

### Plot!

```{r}
# use ggpredict to get marginal means / predicted values
similarity.df <- ggpredict(model.similarity, terms = c("recent.similarity","condType"), ci.lvl = 0.95)
similarity.df <- as.data.frame(similarity.df)

# get point information for plot (mean similarity and mean time chosen per dyad, per clip)
# each point represents average semantic similarity between each contestant pair for each clip
sim <- friend.rival %>%
  group_by(dyad, ClipNumber, condType) %>%
  summarize(mean.similarity = mean(recent.similarity),
            mean.TimeChosen = mean(percent.chosen))

# plot!
ggplot(data = similarity.df, aes(y = predicted, x = x, color = group, fill = group)) +
  geom_point(data = sim, 
             aes(x = mean.similarity, y = mean.TimeChosen, color = condType, fill = condType), 
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0, 1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = conf.low, ymax = conf.high),
              linetype = .5) +
  ylab("% time chosen") +
  xlab("dyadic-level semantic similarity") +
  theme_classic() +
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

ggsave(filename = "Study2-similarity.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-similarity.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

similarity.plot <- last_plot()
```

### Re-reference

```{r}
# re-run with rival as reference
friend.rival$condType <- as.factor(friend.rival$condType)
friend.rival <- within(friend.rival, condType <- relevel(condType, ref = "Rival"))

model2.similarity <- lmer(percent.chosen ~ recent.similarity * condType + (1|dyad) + (1|PID),
                          data = friend.rival)
summary(model2.similarity)
confint(model2.similarity)
```

### Compare interaction model

```{r}
# run multilevel model
model.similarity <- lmer(percent.chosen ~ recent.similarity * condType + (1|dyad) + (1|PID),
                         data = friend.rival)
# run main effect model (null)
null.similarity <- lmer(percent.chosen ~ recent.similarity + condType + (1|dyad) + (1|PID),
                        data = friend.rival)
summary(null.similarity)
confint(null.similarity)

anova(model.similarity, null.similarity)

```

## Standardized Betas

```{r}
# only include friend and rival judgments
friend.rival <- subset(overall_sim, condType != "Win")

# make condType a factor
friend.rival$condType <- as.factor(friend.rival$condType)
test <- subset(overall_sim, condType == "Friend")

# standardize percent.chosen and recent.similarity
friend.rival$percent.chosenZ <- as.numeric(scale(friend.rival$percent.chosen))
friend.rival$recent.similarityZ <- as.numeric(scale(friend.rival$recent.similarity))

# run multilevel model
model.similarity <- lmer(percent.chosenZ ~ recent.similarityZ * condType + (1|dyad) + (1|PID),
                         data = friend.rival)

summary(model.similarity)
# get confidence intervals
confint(model.similarity)
# get simple slopes
simple_slopes(model.similarity)

# compare to null model
null.similarity <- lmer(percent.chosenZ ~ recent.similarityZ + condType + (1|dyad) + (1|PID),
                        data = friend.rival)
summary(null.similarity)
confint(null.similarity)

anova(model.similarity, null.similarity)
```



***

## Sentiment / Clout

**Note: Sentiment and clout are within-person (in this case, within Target) mean-centered (not grand mean centered). This allows me to capture variations relative to each Target's average, rather than relative to the grand mean.**

### Format data

```{r}
# get mean % time chosen per clip, averaged across participants
all_choices <- df.ling %>%
  select(Target, ChoiceOption, ClipNumber, PID, BlockType, 
         percent.chosen, recent.sentiment, recent.clout, mean.wordcount)

# add "Speaker" and "Recipient" columns
all_choices$Speaker <- all_choices$Target
all_choices$Recipient <- all_choices$ChoiceOption

# make sure PID is a factor
all_choices$PID <- as.factor(all_choices$PID)

# mean center both recent.sentiment and recent.clout scores
# (centering within target)
all_choices <- isolate(all_choices, by = "Target",
                value = c("recent.sentiment","recent.clout"),
                which = "within")
# rename
names(all_choices)[12] <- "MC_recent.sentiment"
names(all_choices)[13] <- "MC_recent.clout"
```

Not every contestant speaks to each other in each clip, so we have fewer points for sentiment and clout than for the similarity plot. 

Look at simple slopes for when BlockType is friend and rival. This indicates the relationship between sentiment and % of time chosen when in a friend block or a rival block. I am testing if that value is significantly different from zero. Sentiment/clout is the moderator!

### Sentiment

```{r}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")

# set up linear mixed effects model
model.sentiment <- lmer(percent.chosen ~ BlockType * MC_recent.sentiment + 
                          (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model.sentiment)
# get confidence intervals
confint(model.sentiment)
# get simple slopes
simple_slopes(model.sentiment)
# plot simple slopes
graph_model(model.sentiment, y=percent.chosen, x=BlockType, lines=MC_recent.sentiment, colors = fr.colors)
```

#### Plot!

```{r}
# use ggpredict to get marginal means / predicted values
sentiment.df <- ggpredict(model.sentiment, terms = c("MC_recent.sentiment","BlockType"), ci.lvl = 0.95)
sentiment.df <- as.data.frame(sentiment.df)

# get point information for plot (mean sentiment and mean time chosen per speaker/recipient pair, per clip)
# each point represents average sentiment for each speaker/recipient pair for each clip
sent <- friend.rival %>%
  group_by(Target, ChoiceOption, ClipNumber, BlockType) %>%
  summarize(mean.MC_sentiment = mean(MC_recent.sentiment),
            mean.TimeChosen = mean(percent.chosen))

# plot!
ggplot(data = as.data.frame(sentiment.df),
       aes(y = predicted, x = x, color = group, fill = group)) +
  geom_point(data = sent, 
             aes(x = mean.MC_sentiment, y = mean.TimeChosen, color = BlockType, fill = BlockType),
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0, 1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = conf.low, ymax = conf.high),
              linetype = .5) +
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  xlab("mean-centered sentiment") +
  ylab("% time chosen") + theme_classic() +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

ggsave(filename = "Study2-sentiment.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-sentiment.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

sentiment.plot <- last_plot()

```

#### Re-reference

```{r}
# re-run with rival as reference
friend.rival$BlockType <- as.factor(friend.rival$BlockType)
friend.rival <- within(friend.rival, BlockType <- relevel(BlockType, ref = "Rival"))

model2.sentiment <- lmer(percent.chosen ~ BlockType * MC_recent.sentiment + 
                          (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model2.sentiment)
confint(model2.sentiment)
```

### Compare interaction model

```{r}
# run multilevel model
model.sentiment <- lmer(percent.chosen ~ BlockType * MC_recent.sentiment + 
                          (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
# run main effect model (null)
null.sentiment <- lmer(percent.chosen ~ BlockType + MC_recent.sentiment + (1|Speaker) + (1|Recipient) + (1|PID),
                        data = friend.rival)
summary(null.sentiment)
confint(null.sentiment)

anova(model.sentiment, null.sentiment)

```

## Standardized Betas

```{r}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")

# standardize percent chosen & sentiment
friend.rival$percent.chosenZ <- as.numeric(scale(friend.rival$percent.chosen))
friend.rival$MC_recent.sentimentZ <- as.numeric(scale(friend.rival$MC_recent.sentiment))

# set up linear mixed effects model
model.sentiment <- lmer(percent.chosenZ ~ BlockType * MC_recent.sentimentZ+ 
                          (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model.sentiment)
# get confidence intervals
confint(model.sentiment)
# get simple slopes
simple_slopes(model.sentiment)

# compare to null model
null.sentiment <- lmer(percent.chosenZ ~ BlockType + MC_recent.sentimentZ + (1|Speaker) + (1|Recipient) + (1|PID),
                        data = friend.rival)
summary(null.sentiment)
confint(null.sentiment)

anova(model.sentiment, null.sentiment)

```


***

### Clout

```{r}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")

# set up linear mixed effects model
model.clout <- lmer(percent.chosen ~ BlockType * MC_recent.clout + 
                    (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model.clout)
# get confidence intervals
confint(model.clout)
# get simple slopes
simple_slopes(model.clout)
# plot simple slopes
graph_model(model.clout, y=percent.chosen, x=BlockType, lines=MC_recent.clout, colors = fr.colors)
```

#### Plot!
```{r}
# use ggpredict to get marginal means / predicted values
clout.df <- ggpredict(model.clout, terms = c("MC_recent.clout","BlockType"), ci.lvl = 0.95)
clout.df <- as.data.frame(clout.df)

# get point information for plot (mean clout and mean time chosen per speaker/recipient pair, per clip)
# each point represents average clout for each speaker/recipient pair for each clip
clout <- friend.rival %>%
  group_by(Target, ChoiceOption, ClipNumber, BlockType) %>%
  summarize(mean.MC_clout = mean(MC_recent.clout),
            mean.TimeChosen = mean(percent.chosen))

# plot!
ggplot(data = as.data.frame(clout.df),
       aes(y = predicted, x = x, color = group, fill = group)) +
  geom_point(data = clout, 
             aes(x = mean.MC_clout, y = mean.TimeChosen, color = BlockType, fill = BlockType),
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0, 1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = conf.low, ymax = conf.high),
              linetype = .5) +
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  xlab("mean-centered clout") +
  ylab("% time chosen") + theme_classic() +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

ggsave(filename = "Study2-clout.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-clout.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

clout.plot <- last_plot()

```

#### Re-reference

```{r}
# re-run with rival as reference
friend.rival$BlockType <- as.factor(friend.rival$BlockType)
friend.rival <- within(friend.rival, BlockType <- relevel(BlockType, ref = "Rival"))

model2.clout <- lmer(percent.chosen ~ BlockType * MC_recent.clout + 
                    (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model2.clout)
confint(model2.clout)
```

### Compare interaction model

```{r}
# run multilevel model
model.clout <- lmer(percent.chosen ~ BlockType * MC_recent.clout + 
                    (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
# run main effect model (null)
null.clout <- lmer(percent.chosen ~ BlockType + MC_recent.clout + 
                     (1|Speaker) + (1|Recipient) + (1|PID),
                     data = friend.rival)

anova(model.clout, null.clout)

```

## Standardized Betas

```{r}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")

# standardize percent.chosen and MC_recent.clout
friend.rival$percent.chosenZ <- as.numeric(scale(friend.rival$percent.chosen))
friend.rival$MC_recent.cloutZ <- as.numeric(scale(friend.rival$MC_recent.clout))

# set up linear mixed effects model
model.clout <- lmer(percent.chosenZ ~ BlockType * MC_recent.cloutZ + 
                    (1|PID) + (1|Speaker) + (1|Recipient),
                    data = friend.rival)
summary(model.clout)
# get confidence intervals
confint(model.clout)
# get simple slopes
simple_slopes(model.clout)

null.clout <- lmer(percent.chosenZ ~ BlockType + MC_recent.cloutZ + 
                     (1|Speaker) + (1|Recipient) + (1|PID),
                     data = friend.rival)
summary(null.clout)
confint(null.clout)

anova(model.clout, null.clout)
```


## Save multi panel plot for linguistic features

```{r}
# patchwork plot and save
patchwork <- (similarity.plot + sentiment.plot + clout.plot)
patchwork + plot_layout(guides = "collect") & plot_annotation(tag_levels = "A") & theme(plot.tag = element_text(size = 14, face = "bold")) 

ggsave(filename = "Study2-all-features.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 15, height = 5,
       units = c("in"))

ggsave(filename = "Study2-all-features.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 15, height = 5,
       units = c("in"))
```

# Supplemental: Bayesian approach to examine singularity

We took a Bayesian approach in order to establish that singularity would not undermine the validity of the models. Singularity typically occurs when there is limited variability within the random effects term(s) and/or the random effects structure is overly-complex relative to the variability offered by the data. Given the nature of our data, we opted to retain our random effects in all frequentist models after examining the same models with a Bayesian approach (using uninformative/default priors, which should, and do, yield the same beta estimates as a frequentist approach).

## Similarity
```{r brms1}
library(bayesplot)
library(brms)
library(tidybayes)
# only include friend and rival judgments
friend.rival <- subset(overall_sim, condType != "Win")
sim.friendRival <- subset(sim, condType != "Win")

model.similarity.brms <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ recent.similarity * condType + (1|dyad) + (1|PID), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

summary(model.similarity.brms, waic = TRUE)
conditional_effects(model.similarity.brms)
pairs(model.similarity.brms)
plot(model.similarity.brms)

model.similarity.brms %>% 
  neff_ratio() %>% 
  mcmc_neff_hist(binwidth = .1) +
  yaxis_text()

#main effect model for comparison
model.similarity.brms.main <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ recent.similarity + condType + (1|dyad) + (1|PID), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

#model comparison via loo
model.similarity.brms <- add_criterion(model.similarity.brms, "loo")
model.similarity.brms.main <- add_criterion(model.similarity.brms.main, "loo")

loo_compare(model.similarity.brms, model.similarity.brms.main) %>% 
  print(simplify = F)

# plot to save
c_similarity <- conditional_effects(model.similarity.brms,
                    effects = "recent.similarity:condType")
c_similarity <- as.data.frame(c_similarity$`recent.similarity:condType`)

ggplot(c_similarity, aes(x = recent.similarity, y = estimate__, color = condType, fill = condType)) +
  geom_point(data = sim.friendRival,
             aes(x = mean.similarity, y = mean.TimeChosen, color = condType, fill = condType),
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0,1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = lower__, ymax = upper__),
              linetype = 0.5) +
  ylab("% time chosen") +
  xlab("dyadic-level semantic similarity") +
  theme_classic() + 
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

similarity.bayesplot <- last_plot()

ggsave(filename = "Study2-bayes-similarity.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-bayes-similarity.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))
```

## Sentiment
```{r brms2}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")
sent.friendRival <- subset(sent, BlockType != "Win")

model.sentiment.brms <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ BlockType * MC_recent.sentiment + 
                          (1|PID) + (1|Speaker) + (1|Recipient), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

summary(model.sentiment.brms, waic = TRUE)
conditional_effects(model.sentiment.brms)
pairs(model.sentiment.brms)
plot(model.sentiment.brms)

model.sentiment.brms %>% 
  neff_ratio() %>% 
  mcmc_neff_hist(binwidth = .1) +
  yaxis_text()

#main effect model
model.sentiment.brms.main <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ BlockType + MC_recent.sentiment + 
                          (1|PID) + (1|Speaker) + (1|Recipient), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

summary(model.sentiment.brms.main, waic = TRUE)

#model comparison via loo
model.sentiment.brms <- add_criterion(model.sentiment.brms, "loo")
model.sentiment.brms.main <- add_criterion(model.sentiment.brms.main, "loo")

loo_compare(model.sentiment.brms, model.sentiment.brms.main) %>% 
  print(simplify = F)

# plot to save
c_sentiment <- conditional_effects(model.sentiment.brms,
                    effects = "MC_recent.sentiment:BlockType")
c_sentiment <- as.data.frame(c_sentiment$`MC_recent.sentiment:BlockType`)

ggplot(c_sentiment, aes(x = MC_recent.sentiment, y = estimate__, color = BlockType, fill = BlockType)) +
  geom_point(data = sent.friendRival,
             aes(x = mean.MC_sentiment, y = mean.TimeChosen, color = BlockType, fill = BlockType),
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0,1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = lower__, ymax = upper__),
              linetype = 0.5) +
  ylab("% time chosen") +
  xlab("mean-centered sentiment") +
  theme_classic() + 
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

sentiment.bayesplot <- last_plot()

ggsave(filename = "Study2-bayes-sentiment.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-bayes-sentiment.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

```


## Clout
```{r brms3}
# only include friend and rival judgments
friend.rival <- subset(all_choices, BlockType != "Win")
clout.friendRival <- subset(clout, BlockType != "Win")

model.clout.brms <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ BlockType * MC_recent.clout + 
                          (1|PID) + (1|Speaker) + (1|Recipient), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

summary(model.clout.brms, waic = TRUE)
conditional_effects(model.clout.brms)
pairs(model.clout.brms)
plot(model.clout.brms)

model.clout.brms %>% 
  neff_ratio() %>% 
  mcmc_neff_hist(binwidth = .1) +
  yaxis_text()

#main effect model for comparison
model.clout.brms.main <- brm(data = friend.rival,
      family = gaussian,
      percent.chosen ~ BlockType + MC_recent.clout + 
                          (1|PID) + (1|Speaker) + (1|Recipient), 
      iter = 4000, warmup = 1500, chains = 3, cores = 3,
      control = list(adapt_delta = .999, max_treedepth = 15), 
      seed = 9)

summary(model.clout.brms.main, waic = TRUE)

#model comparison via loo
model.clout.brms <- add_criterion(model.clout.brms, "loo")
model.clout.brms.main <- add_criterion(model.clout.brms.main, "loo")

loo_compare(model.clout.brms, model.clout.brms.main) %>% 
  print(simplify = F)

# plot to save
c_clout <- conditional_effects(model.clout.brms,
                    effects = "MC_recent.clout:BlockType")
c_clout <- as.data.frame(c_clout$`MC_recent.clout:BlockType`)

ggplot(c_clout, aes(x = MC_recent.clout, y = estimate__, color = BlockType, fill = BlockType)) +
  geom_point(data = clout.friendRival,
             aes(x = mean.MC_clout, y = mean.TimeChosen, color = BlockType, fill = BlockType),
             alpha = 0.5, shape = 16) +
  geom_line(size = 1.5) +
  ylim(0,1) +
  geom_ribbon(alpha = my.alpha,
              aes(ymin = lower__, ymax = upper__),
              linetype = 0.5) +
  ylab("% time chosen") +
  xlab("mean-centered clout") +
  theme_classic() + 
  scale_color_manual(values = fr.colors, name = "Group") +
  scale_fill_manual(values = fr.colors, name = "Group") +
  theme(panel.background = element_blank(),
        axis.title.x = element_text(vjust = -0.4, size = 16),
        axis.title.y = element_text(vjust = 1.5, size = 16), 
        axis.text = element_text(size = 12),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12))

clout.bayesplot <- last_plot()

ggsave(filename = "Study2-bayes-clout.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

ggsave(filename = "Study2-bayes-clout.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 7, height = 5,
       units = c("in"))

```

## Plot all three!

```{r}
# patchwork plot and save
patchwork <- (similarity.bayesplot + sentiment.bayesplot + clout.bayesplot)
patchwork + plot_layout(guides = "collect") & plot_annotation(tag_levels = "A") & theme(plot.tag = element_text(size = 14, face = "bold")) 

ggsave(filename = "Study2-Bayes-all-features.pdf",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 15, height = 5,
       units = c("in"))

ggsave(filename = "Study2-Bayes-all-features.jpeg",
       path = "/Volumes/GoogleDrive/My Drive/SANLab/Manuscripts/Survivor+Language/MarkdownFigures",
       width = 15, height = 5,
       units = c("in"))
```

